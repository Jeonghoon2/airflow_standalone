[2024-07-29T12:28:03.620+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T12:28:03.633+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T12:28:03.637+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T12:28:03.637+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T12:28:03.643+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-27 02:10:00+00:00
[2024-07-29T12:28:03.646+0900] {standard_task_runner.py:64} INFO - Started process 71594 to run task
[2024-07-29T12:28:03.648+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-27T02:10:00+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmpdhn3m411']
[2024-07-29T12:28:03.650+0900] {standard_task_runner.py:91} INFO - Job 506: Subtask get_data
[2024-07-29T12:28:03.665+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T12:28:03.689+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-27T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-27T02:10:00+00:00'
[2024-07-29T12:28:03.689+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T12:28:03.694+0900] {logging_mixin.py:188} INFO - 2024-07-27
[2024-07-29T12:28:03.694+0900] {logging_mixin.py:188} INFO - {'conf': <airflow.configuration.AirflowConfigParser object at 0x1008e61d0>, 'dag': <DAG: movie>, 'dag_run': <DagRun movie @ 2024-07-27 02:10:00+00:00: scheduled__2024-07-27T02:10:00+00:00, state:running, queued_at: 2024-07-29 03:27:39.374684+00:00. externally triggered: False>, 'data_interval_end': DateTime(2024, 7, 28, 2, 10, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2024, 7, 27, 2, 10, 0, tzinfo=Timezone('UTC')), 'ds_nodash': '20240727', 'execution_date': <Proxy at 0x1083af440 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'execution_date', DateTime(2024, 7, 27, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2024, 7, 27, 2, 10, 0, tzinfo=Timezone('UTC')), 'macros': <module 'airflow.macros' from '/Users/DE32/.pyenv/versions/3.11.9/envs/note/lib/python3.11/site-packages/airflow/macros/__init__.py'>, 'map_index_template': None, 'next_ds': <Proxy at 0x10840e4c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'next_ds', '2024-07-28')>, 'next_ds_nodash': <Proxy at 0x10646bd40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'next_ds_nodash', '20240728')>, 'next_execution_date': <Proxy at 0x10842eac0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'next_execution_date', DateTime(2024, 7, 28, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'outlets': [], 'params': {}, 'prev_data_interval_start_success': DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')), 'prev_data_interval_end_success': DateTime(2024, 7, 25, 2, 10, 0, tzinfo=Timezone('UTC')), 'prev_ds': <Proxy at 0x10842fbc0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'prev_ds', '2024-07-26')>, 'prev_ds_nodash': <Proxy at 0x10846d640 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'prev_ds_nodash', '20240726')>, 'prev_execution_date': <Proxy at 0x10846d940 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'prev_execution_date', DateTime(2024, 7, 26, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'prev_execution_date_success': <Proxy at 0x10846da00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'prev_execution_date_success', DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'prev_start_date_success': DateTime(2024, 7, 29, 3, 27, 7, 171179, tzinfo=Timezone('UTC')), 'prev_end_date_success': DateTime(2024, 7, 29, 3, 27, 57, 965131, tzinfo=Timezone('UTC')), 'run_id': 'scheduled__2024-07-27T02:10:00+00:00', 'task': <Task(PythonOperator): get_data>, 'task_instance': <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, 'task_instance_key_str': 'movie__get_data__20240727', 'test_mode': False, 'ti': <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, 'tomorrow_ds': <Proxy at 0x10846dac0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'tomorrow_ds', '2024-07-28')>, 'tomorrow_ds_nodash': <Proxy at 0x10846db80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'tomorrow_ds_nodash', '20240728')>, 'triggering_dataset_events': <Proxy at 0x1083b7f40 with factory <function _get_template_context.<locals>.get_triggering_events at 0x1083a9440>>, 'ts': '2024-07-27T02:10:00+00:00', 'ts_nodash': '20240727T021000', 'ts_nodash_with_tz': '20240727T021000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': <Proxy at 0x10846dc40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'yesterday_ds', '2024-07-26')>, 'yesterday_ds_nodash': <Proxy at 0x10846dd00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x1063c0e00>, 'yesterday_ds_nodash', '20240726')>, 'templates_dict': None}
[2024-07-29T12:28:03.694+0900] {python.py:237} INFO - Done. Returned value was: None
[2024-07-29T12:28:03.695+0900] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-29T12:28:03.696+0900] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=movie, task_id=get_data, run_id=scheduled__2024-07-27T02:10:00+00:00, execution_date=20240727T021000, start_date=20240729T032803, end_date=20240729T032803
[2024-07-29T12:28:03.710+0900] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-07-29T12:28:03.719+0900] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-29T12:28:03.719+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T14:50:30.466+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T14:50:30.479+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T14:50:30.483+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T14:50:30.483+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T14:50:30.490+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-27 02:10:00+00:00
[2024-07-29T14:50:30.495+0900] {standard_task_runner.py:64} INFO - Started process 78252 to run task
[2024-07-29T14:50:30.498+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-27T02:10:00+00:00', '--job-id', '534', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmpvi440rm7']
[2024-07-29T14:50:30.500+0900] {standard_task_runner.py:91} INFO - Job 534: Subtask get_data
[2024-07-29T14:50:30.518+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T14:50:30.540+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-27T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-27T02:10:00+00:00'
[2024-07-29T14:50:30.540+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T14:50:30.546+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T15:10:51.715+0900] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-07-29T15:10:51.716+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T15:10:51.720+0900] {process_utils.py:132} INFO - Sending 15 to group 78252. PIDs of all processes in the group: [78252]
[2024-07-29T15:10:51.721+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 78252
[2024-07-29T15:11:51.724+0900] {process_utils.py:150} WARNING - process psutil.Process(pid=78252, name='python3.11', status='running', started='14:50:30') did not respond to SIGTERM. Trying SIGKILL
[2024-07-29T15:11:51.724+0900] {process_utils.py:87} INFO - Sending the signal 9 to group 78252
[2024-07-29T15:11:51.727+0900] {process_utils.py:80} INFO - Process psutil.Process(pid=78252, name='python3.11', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='14:50:30') (78252) terminated with exit code -9
[2024-07-29T15:11:51.727+0900] {standard_task_runner.py:176} ERROR - ('Job 534 was killed before it finished (likely due to running out of memory)', 'For more information, see https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#LocalTaskJob-killed')
[2024-07-29T15:12:10.321+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T15:12:10.333+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T15:12:10.337+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T15:12:10.337+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T15:12:10.343+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-27 02:10:00+00:00
[2024-07-29T15:12:10.346+0900] {standard_task_runner.py:64} INFO - Started process 80431 to run task
[2024-07-29T15:12:10.349+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-27T02:10:00+00:00', '--job-id', '535', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmpugmv3pq_']
[2024-07-29T15:12:10.350+0900] {standard_task_runner.py:91} INFO - Job 535: Subtask get_data
[2024-07-29T15:12:10.365+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T15:12:10.386+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-27T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-27T02:10:00+00:00'
[2024-07-29T15:12:10.386+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T15:12:10.391+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T15:15:29.800+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T15:15:29.806+0900] {process_utils.py:132} INFO - Sending 15 to group 80431. PIDs of all processes in the group: [80431]
[2024-07-29T15:15:29.806+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 80431
[2024-07-29T15:15:36.855+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T15:15:36.863+0900] {taskinstance.py:2066} INFO - Dependencies not met for <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, dependency 'Task Instance State' FAILED: Task is in the 'running' state.
[2024-07-29T15:15:36.863+0900] {taskinstance.py:2066} INFO - Dependencies not met for <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, dependency 'Task Instance Not Running' FAILED: Task is in the running state
[2024-07-29T15:15:36.864+0900] {local_task_job_runner.py:163} INFO - Task is not able to be run
[2024-07-29T15:19:17.619+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T15:19:17.627+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T15:19:17.630+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [queued]>
[2024-07-29T15:19:17.630+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T15:19:17.635+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-27 02:10:00+00:00
[2024-07-29T15:19:17.638+0900] {standard_task_runner.py:64} INFO - Started process 81346 to run task
[2024-07-29T15:19:17.641+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-27T02:10:00+00:00', '--job-id', '543', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmphtakaj6y']
[2024-07-29T15:19:17.643+0900] {standard_task_runner.py:91} INFO - Job 543: Subtask get_data
[2024-07-29T15:19:17.661+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T15:19:17.690+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-27T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-27T02:10:00+00:00'
[2024-07-29T15:19:17.691+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T15:19:17.696+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T15:27:52.426+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T15:27:52.435+0900] {process_utils.py:132} INFO - Sending 15 to group 81346. PIDs of all processes in the group: [81346]
[2024-07-29T15:27:52.436+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 81346
[2024-07-29T15:27:59.828+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T15:27:59.835+0900] {taskinstance.py:2066} INFO - Dependencies not met for <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, dependency 'Task Instance State' FAILED: Task is in the 'running' state.
[2024-07-29T15:27:59.838+0900] {taskinstance.py:2066} INFO - Dependencies not met for <TaskInstance: movie.get_data scheduled__2024-07-27T02:10:00+00:00 [running]>, dependency 'Task Instance Not Running' FAILED: Task is in the running state
[2024-07-29T15:27:59.839+0900] {local_task_job_runner.py:163} INFO - Task is not able to be run

[2024-07-29T12:27:13.792+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T12:27:13.804+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T12:27:13.807+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T12:27:13.807+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T12:27:13.813+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-24 02:10:00+00:00
[2024-07-29T12:27:13.816+0900] {standard_task_runner.py:64} INFO - Started process 71572 to run task
[2024-07-29T12:27:13.819+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-24T02:10:00+00:00', '--job-id', '498', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmp7hmqfg7_']
[2024-07-29T12:27:13.820+0900] {standard_task_runner.py:91} INFO - Job 498: Subtask get_data
[2024-07-29T12:27:13.835+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T12:27:13.855+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-24T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-24T02:10:00+00:00'
[2024-07-29T12:27:13.856+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T12:27:13.862+0900] {logging_mixin.py:188} INFO - 2024-07-24
[2024-07-29T12:27:13.862+0900] {logging_mixin.py:188} INFO - {'conf': <airflow.configuration.AirflowConfigParser object at 0x1052721d0>, 'dag': <DAG: movie>, 'dag_run': <DagRun movie @ 2024-07-24 02:10:00+00:00: scheduled__2024-07-24T02:10:00+00:00, state:running, queued_at: 2024-07-29 03:27:07.161316+00:00. externally triggered: False>, 'data_interval_end': DateTime(2024, 7, 25, 2, 10, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')), 'ds_nodash': '20240724', 'execution_date': <Proxy at 0x10ace3900 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'execution_date', DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')), 'macros': <module 'airflow.macros' from '/Users/DE32/.pyenv/versions/3.11.9/envs/note/lib/python3.11/site-packages/airflow/macros/__init__.py'>, 'map_index_template': None, 'next_ds': <Proxy at 0x10d7695c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'next_ds', '2024-07-25')>, 'next_ds_nodash': <Proxy at 0x10d88f100 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'next_ds_nodash', '20240725')>, 'next_execution_date': <Proxy at 0x10d88f440 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'next_execution_date', DateTime(2024, 7, 25, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': <Proxy at 0x10d88efc0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'prev_ds', '2024-07-23')>, 'prev_ds_nodash': <Proxy at 0x10d8b3040 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'prev_ds_nodash', '20240723')>, 'prev_execution_date': <Proxy at 0x10d8b3100 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'prev_execution_date', DateTime(2024, 7, 23, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'prev_execution_date_success': <Proxy at 0x10d8b31c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'prev_execution_date_success', None)>, 'prev_start_date_success': None, 'prev_end_date_success': None, 'run_id': 'scheduled__2024-07-24T02:10:00+00:00', 'task': <Task(PythonOperator): get_data>, 'task_instance': <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]>, 'task_instance_key_str': 'movie__get_data__20240724', 'test_mode': False, 'ti': <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]>, 'tomorrow_ds': <Proxy at 0x10d8b3280 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'tomorrow_ds', '2024-07-25')>, 'tomorrow_ds_nodash': <Proxy at 0x10d8b3340 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'tomorrow_ds_nodash', '20240725')>, 'triggering_dataset_events': <Proxy at 0x10d821840 with factory <function _get_template_context.<locals>.get_triggering_events at 0x10d7cfa60>>, 'ts': '2024-07-24T02:10:00+00:00', 'ts_nodash': '20240724T021000', 'ts_nodash_with_tz': '20240724T021000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': <Proxy at 0x10d8b3400 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'yesterday_ds', '2024-07-23')>, 'yesterday_ds_nodash': <Proxy at 0x10d8b34c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x10d7344a0>, 'yesterday_ds_nodash', '20240723')>, 'templates_dict': None}
[2024-07-29T12:27:13.863+0900] {python.py:237} INFO - Done. Returned value was: None
[2024-07-29T12:27:13.863+0900] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-29T12:27:13.865+0900] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=movie, task_id=get_data, run_id=scheduled__2024-07-24T02:10:00+00:00, execution_date=20240724T021000, start_date=20240729T032713, end_date=20240729T032713
[2024-07-29T12:27:13.880+0900] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-07-29T12:27:13.889+0900] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-07-29T12:27:13.889+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T14:12:38.533+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T14:12:38.548+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:12:38.552+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:12:38.552+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T14:12:38.559+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-24 02:10:00+00:00
[2024-07-29T14:12:38.563+0900] {standard_task_runner.py:64} INFO - Started process 75036 to run task
[2024-07-29T14:12:38.566+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-24T02:10:00+00:00', '--job-id', '534', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmpmhsr3v3a']
[2024-07-29T14:12:38.567+0900] {standard_task_runner.py:91} INFO - Job 534: Subtask get_data
[2024-07-29T14:12:38.587+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T14:12:38.617+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-24T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-24T02:10:00+00:00'
[2024-07-29T14:12:38.617+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T14:12:38.623+0900] {logging_mixin.py:188} INFO - 2024-07-24
[2024-07-29T14:12:38.624+0900] {logging_mixin.py:188} INFO - {'conf': <airflow.configuration.AirflowConfigParser object at 0x1012861d0>, 'dag': <DAG: movie>, 'dag_run': <DagRun movie @ 2024-07-24 02:10:00+00:00: scheduled__2024-07-24T02:10:00+00:00, state:running, queued_at: 2024-07-29 05:12:31.000615+00:00. externally triggered: False>, 'data_interval_end': DateTime(2024, 7, 25, 2, 10, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')), 'ds_nodash': '20240724', 'execution_date': <Proxy at 0x106a65380 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'execution_date', DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2024, 7, 24, 2, 10, 0, tzinfo=Timezone('UTC')), 'macros': <module 'airflow.macros' from '/Users/DE32/.pyenv/versions/3.11.9/envs/note/lib/python3.11/site-packages/airflow/macros/__init__.py'>, 'map_index_template': None, 'next_ds': <Proxy at 0x105854b00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'next_ds', '2024-07-25')>, 'next_ds_nodash': <Proxy at 0x106dbbb80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'next_ds_nodash', '20240725')>, 'next_execution_date': <Proxy at 0x106eaaa80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'next_execution_date', DateTime(2024, 7, 25, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': <Proxy at 0x106eab980 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'prev_ds', '2024-07-23')>, 'prev_ds_nodash': <Proxy at 0x106eb0e40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'prev_ds_nodash', '20240723')>, 'prev_execution_date': <Proxy at 0x106edd9c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'prev_execution_date', DateTime(2024, 7, 23, 2, 10, 0, tzinfo=Timezone('UTC')))>, 'prev_execution_date_success': <Proxy at 0x106edda80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'prev_execution_date_success', None)>, 'prev_start_date_success': None, 'prev_end_date_success': None, 'run_id': 'scheduled__2024-07-24T02:10:00+00:00', 'task': <Task(PythonOperator): get_data>, 'task_instance': <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]>, 'task_instance_key_str': 'movie__get_data__20240724', 'test_mode': False, 'ti': <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]>, 'tomorrow_ds': <Proxy at 0x106eddb40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'tomorrow_ds', '2024-07-25')>, 'tomorrow_ds_nodash': <Proxy at 0x106eddc00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'tomorrow_ds_nodash', '20240725')>, 'triggering_dataset_events': <Proxy at 0x106e404c0 with factory <function _get_template_context.<locals>.get_triggering_events at 0x106e34c20>>, 'ts': '2024-07-24T02:10:00+00:00', 'ts_nodash': '20240724T021000', 'ts_nodash_with_tz': '20240724T021000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': <Proxy at 0x106eddcc0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'yesterday_ds', '2024-07-23')>, 'yesterday_ds_nodash': <Proxy at 0x106eddd80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x106d4c4a0>, 'yesterday_ds_nodash', '20240723')>, 'templates_dict': None}
[2024-07-29T14:12:38.624+0900] {logging_mixin.py:188} INFO - ds_nodash => 20240724
[2024-07-29T14:12:38.624+0900] {logging_mixin.py:188} INFO - kwargs type => <class 'dict'>
[2024-07-29T14:12:38.624+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T14:14:34.113+0900] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2024-07-29T14:14:34.113+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T14:14:34.118+0900] {process_utils.py:132} INFO - Sending 15 to group 75036. PIDs of all processes in the group: [75036]
[2024-07-29T14:14:34.118+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 75036
[2024-07-29T14:15:34.151+0900] {process_utils.py:150} WARNING - process psutil.Process(pid=75036, name='python3.11', status='running', started='14:12:38') did not respond to SIGTERM. Trying SIGKILL
[2024-07-29T14:15:34.152+0900] {process_utils.py:87} INFO - Sending the signal 9 to group 75036
[2024-07-29T14:15:34.154+0900] {process_utils.py:80} INFO - Process psutil.Process(pid=75036, name='python3.11', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='14:12:38') (75036) terminated with exit code -9
[2024-07-29T14:15:34.154+0900] {standard_task_runner.py:176} ERROR - ('Job 534 was killed before it finished (likely due to running out of memory)', 'For more information, see https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#LocalTaskJob-killed')
[2024-07-29T14:32:13.348+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T14:32:13.361+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:32:13.365+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:32:13.366+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T14:32:13.372+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-24 02:10:00+00:00
[2024-07-29T14:32:13.375+0900] {standard_task_runner.py:64} INFO - Started process 76808 to run task
[2024-07-29T14:32:13.378+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-24T02:10:00+00:00', '--job-id', '535', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmpe9ebd7ep']
[2024-07-29T14:32:13.380+0900] {standard_task_runner.py:91} INFO - Job 535: Subtask get_data
[2024-07-29T14:32:13.398+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T14:32:13.420+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-24T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-24T02:10:00+00:00'
[2024-07-29T14:32:13.420+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T14:32:13.425+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T14:33:03.661+0900] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-07-29T14:33:03.662+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T14:33:03.667+0900] {process_utils.py:132} INFO - Sending 15 to group 76808. PIDs of all processes in the group: [76808]
[2024-07-29T14:33:03.668+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 76808
[2024-07-29T14:34:03.684+0900] {process_utils.py:150} WARNING - process psutil.Process(pid=76808, name='python3.11', status='running', started='14:32:13') did not respond to SIGTERM. Trying SIGKILL
[2024-07-29T14:34:03.684+0900] {process_utils.py:87} INFO - Sending the signal 9 to group 76808
[2024-07-29T14:34:03.686+0900] {process_utils.py:80} INFO - Process psutil.Process(pid=76808, name='python3.11', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='14:32:13') (76808) terminated with exit code -9
[2024-07-29T14:34:03.687+0900] {standard_task_runner.py:176} ERROR - ('Job 535 was killed before it finished (likely due to running out of memory)', 'For more information, see https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#LocalTaskJob-killed')
[2024-07-29T14:40:21.938+0900] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-29T14:40:21.951+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:40:21.954+0900] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [queued]>
[2024-07-29T14:40:21.954+0900] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-29T14:40:21.960+0900] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): get_data> on 2024-07-24 02:10:00+00:00
[2024-07-29T14:40:21.963+0900] {standard_task_runner.py:64} INFO - Started process 77215 to run task
[2024-07-29T14:40:21.966+0900] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'movie', 'get_data', 'scheduled__2024-07-24T02:10:00+00:00', '--job-id', '536', '--raw', '--subdir', 'DAGS_FOLDER/movie.py', '--cfg-path', '/var/folders/qv/0knwm5h50ml0skpppwpbks_r0000gp/T/tmp_qht32yj']
[2024-07-29T14:40:21.967+0900] {standard_task_runner.py:91} INFO - Job 536: Subtask get_data
[2024-07-29T14:40:21.983+0900] {task_command.py:426} INFO - Running <TaskInstance: movie.get_data scheduled__2024-07-24T02:10:00+00:00 [running]> on host jeongui-MacBookPro.local
[2024-07-29T14:40:22.004+0900] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie' AIRFLOW_CTX_TASK_ID='get_data' AIRFLOW_CTX_EXECUTION_DATE='2024-07-24T02:10:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-24T02:10:00+00:00'
[2024-07-29T14:40:22.004+0900] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-29T14:40:22.008+0900] {logging_mixin.py:188} INFO - ====================
[2024-07-29T14:41:27.328+0900] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2024-07-29T14:41:27.328+0900] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-29T14:41:27.333+0900] {process_utils.py:132} INFO - Sending 15 to group 77215. PIDs of all processes in the group: [77215]
[2024-07-29T14:41:27.333+0900] {process_utils.py:87} INFO - Sending the signal 15 to group 77215
[2024-07-29T14:42:27.338+0900] {process_utils.py:150} WARNING - process psutil.Process(pid=77215, name='python3.11', status='running', started='14:40:21') did not respond to SIGTERM. Trying SIGKILL
[2024-07-29T14:42:27.339+0900] {process_utils.py:87} INFO - Sending the signal 9 to group 77215
[2024-07-29T14:42:27.341+0900] {process_utils.py:80} INFO - Process psutil.Process(pid=77215, name='python3.11', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='14:40:21') (77215) terminated with exit code -9
[2024-07-29T14:42:27.341+0900] {standard_task_runner.py:176} ERROR - ('Job 536 was killed before it finished (likely due to running out of memory)', 'For more information, see https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#LocalTaskJob-killed')
